{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "from urllib import request\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver import ActionChains  \n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "from fake_useragent import UserAgent\n",
    "from tqdm.notebook import trange\n",
    "import time\n",
    "import platform\n",
    "from langdetect import detect\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "#options.add_argument('headless')\n",
    "options.add_experimental_option('excludeSwitches', ['enable-automation']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_user_agent():\n",
    "    ua = UserAgent()\n",
    "    \n",
    "    working = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.1 Safari/605.1.15\"\n",
    "    working_tail = \"(\" + working.split(\"(\")[-1]\n",
    "    random_head = ua.random.split(\"(\")[0]+\"(\"+ua.random.split(\"(\")[1]\n",
    "    return random_head + working_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system()==\"Windows\":\n",
    "    driverpath = os.getcwd()+\"/chromedriver.exe\"\n",
    "else:\n",
    "    driverpath = os.getcwd()+\"/chromedriver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(page, lang = True):\n",
    "        \n",
    "    url = \"https://www.coursera.org/directory/courses?page=\"+ str(page)\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    links = soup.findAll('a', {'class':'c-directory-link'}, href=True)\n",
    "    \n",
    "    course_name = []\n",
    "    course_links = []\n",
    "    for i in links:\n",
    "        if detect(i.text)==\"en\":\n",
    "            course_name.append(i.text)\n",
    "            course_links.append('https://coursera.org' + i[\"href\"])\n",
    "    \n",
    "    collected = {}\n",
    "    for i in range(0, len(course_name)):\n",
    "        collected[course_name[i]] = course_links[i]\n",
    "    return collected\n",
    "\n",
    "def crawl(url):\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    \n",
    "    #Category\n",
    "    category1 = soup.findAll('div', {'class':'_1ruggxy'})[1].text\n",
    "    category2 = soup.findAll('div', {'class':'_1ruggxy'})[2].text\n",
    "   \n",
    "    #Rating, if exists\n",
    "    ratingContainer = soup.findAll('span', {'class':'_16ni8zai m-b-0 rating-text number-rating number-rating-expertise'})\\\n",
    "    +soup.findAll('span', {'class':'_16ni8zai m-b-0 rating-text number-rating m-l-1s m-r-1'})\n",
    "    if ratingContainer != [] and ratingContainer != None:\n",
    "        rating = float(re.sub('[^0-9.]+', '', ratingContainer[0].text))\n",
    "    else:\n",
    "        rating = 'None'\n",
    "        \n",
    "    #Number of Ratings\n",
    "    ratecountContainer = soup.findAll('div', {'class':'_wmgtrl9 color-white ratings-count-expertise-style'})\\\n",
    "    +soup.findAll('div', {'class':'_wmgtrl9 m-r-1s'})\n",
    "    if ratecountContainer != [] and ratecountContainer != None:\n",
    "        ratecount = int(re.sub('[^0-9.]+', '', ratecountContainer[0].text))\n",
    "    else:\n",
    "        ratecount = 'None'\n",
    "    \n",
    "    skills = \"|\".join([i.text for i in soup.findAll(\"span\", {\"class\" :  \"_1q9sh65\"})])\n",
    "    \n",
    "    try:\n",
    "        if soup.findAll('div', {'class':'contents_inner'})+soup.findAll('p', {'class':'_g61i7y'})==[]:\n",
    "            driver.find_element(By.CLASS_NAME, \"overlay\").click()\n",
    "            #time.sleep(1)\n",
    "            soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "        about = \" \".join([i.text for i in soup.findAll('div', {'class':'contents_inner'})+soup.findAll('p', {'class':'_g61i7y'})])\n",
    "    except:\n",
    "        about = \"None\"\n",
    "    \n",
    "    #There are two templates - one includes extra info-tag\n",
    "    infos1 = soup.findAll('div', {'class':'_16ni8zai m-b-0'})\n",
    "    infos2 = soup.findAll('div', {'class':'_16ni8zai m-b-0 m-t-1s'})\n",
    "    infos = list(set([i.text for i in infos1+infos2]))\n",
    "    \n",
    "    #Type1\n",
    "    if infos != [] and infos != None:\n",
    "        infos = infos\n",
    "        type_of_doc = \"type1\"\n",
    "        \n",
    "    #Type2\n",
    "    else:\n",
    "        infos = soup.findAll('span', {'class':'_1rcyblj'}) + soup.findAll('span', {'class':'_1ounhrgz'})\n",
    "        infos = list(set([i.text for i in infos]))\n",
    "        type_of_doc = \"type2\"\n",
    "        \n",
    "        \n",
    "    infos = \"|\".join(infos)\n",
    "    return {\"Category1\": category1, \"Category2\": category2, \"Rating\": rating, \"Ratecount\": ratecount, \"Info\" :  infos, \"skills\" : skills, \"about\" : about, \"type\": type_of_doc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/HongSukhyun/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: use options instead of chrome_options\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14aa4386342041ce89ff14264523aebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(driverpath, chrome_options=options)\n",
    "data = {}\n",
    "for i in range(1, 2):\n",
    "    links = get_links(i, lang = True)\n",
    "    names= list(links.keys())\n",
    "    for c in trange(0, len(names)):\n",
    "        course = names[c]\n",
    "        link = links[course]\n",
    "        data[course] = crawl(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"coursera.json\", \"w\") as json_file:\n",
    "    json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
